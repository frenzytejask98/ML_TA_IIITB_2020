{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Linear Regression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChV9OTMAZtgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49-Vpt1wZtgT",
        "colab_type": "text"
      },
      "source": [
        "Let us first generate data which follows y = 5x + 6 + delta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4AryVRNZtgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate data\n",
        "x = np.random.rand(100)\n",
        "delta = np.random.rand(100)\n",
        "y = 5 * x + 6 + delta\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "# Plot data\n",
        "plt.figure(figsize = (10, 5))\n",
        "plt.plot(x,y, 'b.')\n",
        "plt.xlabel(\"Values of x\")\n",
        "plt.ylabel(\"Values of y\")\n",
        "plt.title(\"X vs Y\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAqkaI--Ztgm",
        "colab_type": "text"
      },
      "source": [
        "Define loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OXPaTA6Ztgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss function\n",
        "def loss(y, y_predicted):\n",
        "    return np.mean(np.square(y-y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO8zeznBZtg0",
        "colab_type": "text"
      },
      "source": [
        "Define Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkhDAlr3Ztg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_grad(x_data, y_data, m, c):\n",
        "    m_grad = np.mean((y_data - (m*x_data+c))*(-x_data))\n",
        "    c_grad = np.mean((y_data - (m*x_data+c))*(-1))\n",
        "    return m_grad, c_grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxuGnuhpZthB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get indices of samples for training, validation and testing\n",
        "indices = np.random.permutation(x.shape[0])\n",
        "training_idx, val_idx, test_idx = indices[:60], indices[60:80], indices[80:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnbwWRPlZthM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split x into training and testing data\n",
        "x_train = x[training_idx]\n",
        "x_val = x[val_idx]\n",
        "x_test = x[test_idx]\n",
        "\n",
        "# Split y into training and testing data\n",
        "y_train = y[training_idx]\n",
        "y_val = y[val_idx]\n",
        "y_test = y[test_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cFbeZ70ZthW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set random.seed value\n",
        "np.random.seed(40)\n",
        "\n",
        "# Initialize m and c values\n",
        "m0 = float(np.random.rand(1))\n",
        "c0 = float(np.random.rand(1))\n",
        "\n",
        "print(m0)\n",
        "print(c0)\n",
        "\n",
        "# Create empty lists to store intermediate m, c, loss functions\n",
        "m_vec = []; c_vec = []; loss_val_vec = []; loss_train_vec = []\n",
        "\n",
        "# NumberOfIterations\n",
        "NumberOfIterations = 500\n",
        "\n",
        "# Learning rate\n",
        "lr = 0.1\n",
        "for i in range(NumberOfIterations):\n",
        "    m_grad, c_grad = get_grad(x_train, y_train, m0, c0)\n",
        "    m0 = m0 - lr * m_grad\n",
        "    c0 = c0 - lr * c_grad\n",
        "    loss_train = loss(y_train, (m0*x_train+c0))\n",
        "    loss_val = loss(y_val, (m0*x_val+c0))\n",
        "    \n",
        "    m_vec.append(m0)\n",
        "    c_vec.append(c0)\n",
        "    loss_val_vec.append(loss_val)\n",
        "    loss_train_vec.append(loss_train)\n",
        "    \n",
        "print(\"Final m and c values are m_final = {:2.2f}, c_final - {:2.2f}\".format(m0,c0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27Crld1kZthe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizing change in m and c with number of iterations\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(m_vec, label='m')\n",
        "plt.plot(c_vec, label='c')\n",
        "plt.title('Change of m and c with iterations')\n",
        "plt.xlabel(\"Number of iterations\")\n",
        "plt.ylabel(\"m/c values\")\n",
        "plt.legend(); plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By2sN_mAZtho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizing loss with number of iterations\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(loss_val_vec, \"r.\", label = \"Validation Loss\")\n",
        "plt.plot(loss_train_vec, \"b.\", label = \"Training Loss\")\n",
        "plt.title('Change in loss with iterations')\n",
        "plt.xlabel(\"Number of iterations\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend(); plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlAs6XGtZthx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizaing final line on data\n",
        "m = m0; c = c0\n",
        "y_pred = m * x_test + c\n",
        "#y_pred = m * x + c\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(x_test, y_test, \"b.\")\n",
        "plt.plot(x_test, y_pred, '-', color = 'r')\n",
        "plt.title('Final values of m & c are m = {:2.2f}, c = {:2.2f}, loss: {:2.2f}'.format(m, c, loss(y_test,y_pred)))\n",
        "plt.xlabel(\"Values of x\")\n",
        "plt.ylabel(\"Values of y\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5ggHioRZth6",
        "colab_type": "text"
      },
      "source": [
        "It's a long process!!! isn't it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1Nj4gLRZth7",
        "colab_type": "text"
      },
      "source": [
        "Let's use sklearn to build the same regression line "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBrv4VxXZth9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary packages\n",
        "import sklearn\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs4G5de-ZtiG",
        "colab_type": "text"
      },
      "source": [
        "Get Linear Regression model object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvsS6CuYZtiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XF2xtAZtiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit linear regression on x and y\n",
        "lm.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq1OdVbyZtiZ",
        "colab_type": "text"
      },
      "source": [
        "It seems dimensions are not correct. Let's check them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g96p9XmpZtib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us check the shape of x\n",
        "print(x_train.shape)\n",
        "\n",
        "# Let us check the shape of xy\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjn8c2bRZtil",
        "colab_type": "text"
      },
      "source": [
        "we need to give shape of (M, N) and not (M, ). So let's reshape them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNyszFNYZtil",
        "colab_type": "text"
      },
      "source": [
        "You need to give column vector for x and y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5G7KpBJZtio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.reshape(-1, 1)\n",
        "y = y.reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGnAO36MZtit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shape of x\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKTq8WkqZti0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shape of y\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JASyhtJ5Zti6",
        "colab_type": "text"
      },
      "source": [
        "Fit linear regression model on data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGzjH-oIZti7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm.fit(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LMYltlaZtjD",
        "colab_type": "text"
      },
      "source": [
        "Get slope and intercept"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILLVAoO_ZtjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lm.intercept_\n",
        "c_pred = lm.intercept_\n",
        "c_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nI3fYn7ZtjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lm.coef_\n",
        "m_pred = lm.coef_\n",
        "m_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rIXIpwYZtjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizaing final line on data\n",
        "\n",
        "y_pred = lm.predict(x_test.reshape(-1,1))\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(x_test, y_test, \"b.\")\n",
        "plt.plot(x_test, y_pred, \"-\", color = 'r')\n",
        "plt.title('Final value of m, c and loss are m = {:2.2f}, c = {:2.2f}, loss: {:2.2f}'.format(m, c, loss(y_test,y_pred)))\n",
        "plt.xlabel(\"Values of x\")\n",
        "plt.ylabel(\"Values of y\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8g7I-LeZtja",
        "colab_type": "text"
      },
      "source": [
        "Using sklearn you need not define loss function and gradient descent. Sklearn takes care of everything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH8cu5ULZtjc",
        "colab_type": "text"
      },
      "source": [
        "### Excercises "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4y4eaIiZtje",
        "colab_type": "text"
      },
      "source": [
        "1.   Build linear regression from scratch using x1, x2, x3 (3 features) and target label(y).\n",
        "2.   Experiement with different learning rates and see how you reach global minima. Does learning rate have effect on number of iteractions?\n",
        "3.   Build linear regression on Kaggle House Prices: Advanced Regression Techniques dataset using any two features of dataset and sklearn. ( Remember pd.read_csv to load csv file?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x0Cd8sIZtje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
